% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmathfont[]{Latin Modern Math}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{arxiv}
\usepackage{orcidlink}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Demo arXiv template},
  pdfauthor={H. Sherry Zhang; Collaborators},
  pdfkeywords={indices, data pipeline, software design},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Demo arXiv template}
\author{
\textbf{H. Sherry Zhang}~\orcidlink{0000-0002-7122-1463}\\Department of
Econometrics and Business Statistics\\Monash University\\Melbourne,
VIC\\\href{mailto:huize.zhang@monash.edu}{huize.zhang@monash.edu}\\\\\\
\textbf{Collaborators}\\Department of Econometrics and Business
Statistics\\Monash University\\Melbourne, VIC\\}
\date{}
\begin{document}
\maketitle
\begin{abstract}
\begin{itemize}
\tightlist
\item
  Indices, useful, quantify severity, early monitoring,
\item
  A huge number of indices have been proposed by domain experts,
  however, a large majority of them are not being adopted, reused, and
  compared in research or in practice.
\item
  One of the reasons for this is the plenty of indices are quite complex
  and there is no obvious easy-to-use implementation to apply them to
  user's data.
\item
  The paper describes a general pipeline framework to construct indices
  from spatio-temporal data,
\item
  This allows all the indices to be constructed through a uniform data
  pipeline and different indices to vary on the details of each step in
  the data pipeline and their orders.
\item
  The pipeline proposed aim to smooth the workflow of index construction
  through breaking down the complicated steps proposed by various
  indices into small building blocks shared by most of the indices.
\item
  The framework will be demonstrated with drought indices as examples,
  but appliable in general to environmental indices constructed from
  multivariate spatio-temporal data
\end{itemize}
\end{abstract}
{\bfseries \emph Keywords}
\def\sep{\textbullet\ }
indices \sep data pipeline \sep 
software design

\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[enhanced, interior hidden, borderline west={3pt}{0pt}{shadecolor}, frame hidden, breakable, sharp corners, boxrule=0pt]}{\end{tcolorbox}}\fi

\newpage

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\textbf{Why index is useful, why people care about indices}

\emph{incorporate the following in why using index: multiple pieces of
information (variables) that need to be taken into account}

Many concepts relevant to decision making cannot be directly measured,
however, they are crucial for resource allocation, early prevention, and
other operational purpose. For example, fire authorities would be
interested to quantify fire risk since bushfires can have a huge impact
on monetary loss, health, and the local ecosystem. Climatologists would
be interested in monitoring the change in global climate since
variability in atmospheric and oceanic conditions has a direct impact on
global weather and climate. Usually this concept of interest is
associated with more than one variables and these variables need to be
integrated to make decisions on the subject matter. A common approach to
quantify concepts like these is to construct an index using these
relevant variables. This allows researchers to compare the quantity of
interest across entities (i.e.~countries, regions) and also cross time.

\textbf{Define what is an index, what is not}

In this article, an index is defined as a tool to quantify a concept of
interest that does not have a direct measure. The concept of interest
doesn't have a direct measure can because it is impractical to measure
at the population level. For example, it would be nearly impossible to
include all the available stocks in the market to characterise stock
market behavior, so indices like Dow Jones Industrial Average, S\&P 500,
and Nasdaq Composite select a representative set of stocks to measure
the overall market behavior. Also belonging to this category are the
economic indices like the Consumer Price Index, where price changes of a
basket of items are weighted to measure inflation. The lack of direct
measure could also because the concept itself is an unobservable human
construction, rather than a physical quantity that can be measured. Many
natural hazard and social concepts falls into this category. This
includes drought indices constructed from meteorological, agricultural,
hydrological, and social-economic variables, e.g.~Standardised
Precipitation Index (SPI) (McKee et al. 1993) and Aggregated Drought
Index (ADI) (Keyantash and Dracup 2004) among others. Social development
indices like Human Development Index (United Nations Development
Programme 2022) and Global Liveability Index (Economist Intelligence
Unit 2019) measure various aspects of the quality of human capital and
urban life.

\emph{still need to tweak the tone a bit: ``they are called index, they
are not the index we will talk about''}

Despite many quantity having the term \emph{index} in their name, they
cannot be technically classified as indices according to the definition
given above. The reason for these quantities to lose their index
memberships is that they are variables can be accurately measured given
the instrument precision. This includes quantities like precipitation of
the driest month or percentage of days when maximum temperature is below
10th percentile. They are measures of precipitation and percentage of
days under specific conditions (dries month, maximum temperature below
10th percentile). They are variables, or indicators, that can be used to
construct indices but are not indices themselves. Similarly, a set of
remote sensing indices are not indices, since they are measures of
electromagnetic wave reflectance. This includes Normalized Difference
Vegetation Index (NDVI) (Tucker 1979), derived from the ratio of
difference over sum on two segments in the spectrum, also called band:
near-infrared (NIR) and red. So are the ``indices'' derived from NDVI,
e.g.~Vegetation Condition Index (Kogan 1995). Notice that this does not
exclude all the construction derived from remotes sensor variables to be
valid indices. For example, Vegetation Drought Response Index (Brown et
al. 2008) is a valid index since it integrates climate, satellite, and
biophysical variables to quantify vegetation stress.

\textbf{What is the challenges with current index construction}

\emph{see if there is any paper describing this type of pains}

\emph{useful to reference tidy data and tidy model that makes the
workflow on modelling tidy somewhere in introduction}

Currently, index construction lacks a standardised workflow. It is often
up to researchers or research institutions to decide whether to provide
open source code on the new indices, what would be the best user
interface for other researchers to use the new indices, and how easily
the new indices can be compared with other existing indices. This makes
the computation lack transparency and indices cumbersome to experiment
with:

\begin{itemize}
\tightlist
\item
  Researchers who wish to validate the indices calculated from large
  institutes need to reinvent the wheels themselves since the source
  code used for computing is often not available for public consumption;
\item
  Open-source code provided by research groups has a narrow margin for
  exploring other options outside the provided;
\item
  Similar steps used by different indices are difficult to spot since
  the design of the user interface for indices often includes all the
  steps under a single function call; and
\item
  It is generally hard to inspect intermediate results during the index
  construction if users wish to check the output of a certain step.
\end{itemize}

\textbf{what can be done if people adopt this pipeline/ why it is
beneficial?}

\emph{first sentence: tailor to their indices without thinking about the
big picture}

\sout{While every jumbled index jumbles in its own way,
{[}perspicuous{]} clearly-laied out indices are all alike.} This paper
proposes a data pipeline for index construction. By recognising the
common steps shared by many indices, we develop a pipeline that breaks
down index construction into multiple modules and allow operations in
various modules to be combined like building blocks to construct
indices. The pipeline approach is general while adaptable to most index
construction. It allows indices to be created, studied, and compared in
a structured tidy form and enables statistical analysis of indices to be
performed easily: More specifically, it enables researchers to 1)
validate the indices calculated from external organisations, 2) unify
various indices under the same framework for computing, 3) swap or
adjust individual steps in the index construction to study their
contribution, 4) calculate uncertainty on indices through bootstrap or
others, 5) enhance existing indices through comparing and studying their
statistical properties, and finally, 6) propose new indices from
combining different steps in existing indices.

\textbf{who would benefit from this paper}

This work is of interest to researchers actively developing new indices
since it encourages new indices to be delivered in an easy-to-reproduce
design. It would also provide analysts who wish to compute a range of
indices in their analysis a uniform interface to build relevant indices
from raw data. For statisticians and software developing engineers, this
work frames the process of index construction in a more user-oriented
workflow and could motivate similar research for other process in
scientific computing.

The rest of the paper is structured as follows:
Section~\ref{sec-data-pipeline-in-r} reviews the concept of data
pipeline in R. The pipeline framework for index construction is
presented in
Section~\ref{sec-a-pipeline-for-building-statistical-indices}.
Section~\ref{sec-incorporating-new-buliding-blocks-into-the-pipeline}
explains how to include a new building block in each pipeline module.
Examples are given in Section~\ref{sec-examples} to demonstrate the
index construction with the pipeline built.

\newpage

\hypertarget{sec-data-pipeline-in-r}{%
\section{Data pipeline in R}\label{sec-data-pipeline-in-r}}

\textbf{Why you should care about pipeline}

Data pipeline is not a new concept to computing. It refers to a set of
data processing elements connected in series, where the output of one
element is the input of the next one. Wickham et al. (2009) argues that
whether made explicit or not, the pipeline has to be presented in every
graphics program. The paper also argues that breaking down graphic
rendering into steps is beneficial for understanding the implementation
and comparing between different graphic systems. The discussion on
pipeline construction is well documented in early interactive graphics
software: Buja et al. (1988), Sutherland et al. (2000), and Xie,
Hofmann, and Cheng (2014) and their pipeline steps include non-linear
transformation, variable standardization, randomization and dimension
reduction.

\textbf{What is pipeline, its underlying software design philosophy, and
how these are reflected in R}

One of the most commonly known pipeline examples is perhaps the Unix
pipeline where programs can be concatenated with \texttt{\textbar{}} to
flow the output from the last program into the next program, i.e.~

\begin{verbatim}
command 1 | command 2 | command 3 | ...
\end{verbatim}

To solve a complex problem, the Unix system builds simple programs that
do one thing well and work well together. This design is also reflected
in the tidyverse ecosystem in R. To solve a complicated data problem
using tidyverse, analysts typically build the solution using a
collection of tools from the tidyverse toolbox. The data object can flow
smoothly from one command to the next, safeguarded by the tidy data
format (Wickham 2014), which prescribes three rules on how to lay out
tabular data. The tidyverse tools also embrace a strong human-centered
design where function names are intuitive and easy to reference through
autocomplete. With the tidyverse design principle in mind, the tidymodel
suite enables analysts to build machine learning models through the data
pipeline. It includes typical tasks required in machine learning like
data resampling, feature engineering, model fitting, model tuning, and
model evaluation. An advantage of tidymodel pipeline over separate
software for individual models is that analysts no longer need to write
model-specific syntax to work with each model, but pipeline-specific
syntax that is applicable to all the models implemented in tidymodel.
This allows users to easily experiment with a collection of machine
learning models.

\textbf{Constructing indices would also benefit from pipeline and
embracing the aforementioned design philosophy.}

In index construction, data pipeline is often presented in a workflow
diagram in the research paper to illustrate how the raw data is
transformed into the final indices. This agrees with Wickham's argument
on the presence of the data pipeline, however, more often than not, the
pipeline is not made explicit in the software. Often the time, all the
steps are lumped into a single wrapper function, rather than being split
into smaller, modulated functions. This increases the cost of
maintaining and understanding the code base, gives analysts little
freedom to customise the indices for specific needs, and hinders reusing
existing code for building new indices. A pipeline approach unites a
range of indices under a single data pipeline and analysts can compose
indices from pipeline steps like building Legos from individual bricks.
In this workflow, analysts are not limited by indices that have been
already proposed and can easily combine pipeline steps to compose novel
indices. Analysis of the indices (i.e.~calculation of uncertainty) is
also feasible by adding external code into the pipeline.

\newpage

\hypertarget{sec-a-pipeline-for-building-statistical-indices}{%
\section{A pipeline for building statistical
indices}\label{sec-a-pipeline-for-building-statistical-indices}}

\hypertarget{how-does-the-pipeline-constructin-of-an-index-look-like}{%
\subsection{How does the pipeline constructin of an index look
like?}\label{how-does-the-pipeline-constructin-of-an-index-look-like}}

Consider a commonly used drought index: Standardised Precipitation Index
(SPI) (McKee, Doesken, and Kleist 1993). Its construction involves: 1)
aggregating monthly precipitation (\texttt{prcp}) with a time scale, 2)
fitting the aggregated series with a chosen distribution to get density
values, and 3) converting the density values to normal quantiles. Under
the pipeline approach, SPI will be constructed as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DATA }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{aggregate}\NormalTok{(}\AttributeTok{scale =} \DecValTok{12}\NormalTok{, }\AttributeTok{var =}\NormalTok{ prcp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{normalise}\NormalTok{(}\AttributeTok{dist =}\NormalTok{ gamma, }\AttributeTok{var =}\NormalTok{ prcp, }\AttributeTok{fit\_method =}\NormalTok{ lmom) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{augment}\NormalTok{(}\AttributeTok{var =}\NormalTok{ .agg\_prcp)}
\end{Highlighting}
\end{Shaded}

Here each command corresponds to one step described above with
additional arguments specific to the step. The pipeline construction
produces the same index value as command like \texttt{spi(...)}, as
shown in Figure~\ref{fig-toy-example}, but with additional benefit:

\begin{itemize}
\tightlist
\item
  Multiple scales and multiple distributions can be fitted using the
  \texttt{c(...)} syntax to compare index values constructed from
  different parameterisations;
\item
  Intermediate results can be checked after each step; and
\item
  Additional steps and analysis can be wired into the workflow for index
  diagnostics and customised user need.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.7\textwidth,height=0.7\textheight]{../figures/toy-example-spi.png}

}

\caption{\label{fig-toy-example}Standardised Precipitation Index (SPI)
calculated using two approaches: the pipeline construction (y-axis) and
the function \texttt{spi()} from the \texttt{SPEI} package (x-axis),
using the \texttt{wichita} data from the package \texttt{SPEI}. All the
points align diagnally, indicating the same numerical result from both
approaches.}

\end{figure}

\hypertarget{pipeline-steps-for-constructing-indies}{%
\subsection{Pipeline steps for constructing
indies}\label{pipeline-steps-for-constructing-indies}}

\emph{put a diagram here to summarise the pipeline}

The construction of natural hazard indices also follows a set of steps,
which is usually illustrated using a flowchart in the paper. However,
every researcher follows a certain design philosophy and steps taken in
the index constructed by different researchers are not aligned. This
discourages experiment with multiple indices. Initiate a new workflow
when computing a new index.

The most popular indices (i.e.~SPI, SPEI, etc) have existing software
implementation (\texttt{SPEI}) to be applied to a different set of data.

constructing time series index should also be encapsulated in my
framework

Here we assume a concept of interest is determined, relevant variables/
indicators are identified and available to construct indices.

each step as a point rather than subsection

\textbf{Raw data}

\emph{Another section on original data directly downloaded, can have
different spatial resolution, temporal granularity, data quality
problem. After processing them and align them together they become the
``raw data''}

The data used to construct the natural hazard index usually have three
dimensions, one for location, one for time, and one for multivariate.
Mathematically, it can be written as \(X_{j, s, t}\), where
\(j = 1, 2, \cdots, J\) for variable, \(s = 1, 2, \cdots, S\) for
location, and \(t = 1, 2, \cdots, T\) for time.

The location \(s\) can refer to vector points or areas characterised by
longitude-latitude coordinates, or raster cells obtained from satellite
images.

The time dimension \(t\) can be daily, weekly, biweekly (14-16 days),
monthly, or even quarterly

Variables

This multidimensional array structure is commonly used in geospatial
analysis

Given the variety of data sources at different spatial resolution and
temporal granularity, the raw data may first come in multiple pieces.
Sometimes, even a considerable amount of work is needed to align the
spatial and temporal extent of multivariate data.

A notation for different variables have different spatial and temporal
granularity \(X_{j_1, s_1, t_1}\)???

\textbf{Spatial aggregation}

mostly happen with raster data

\textbf{Scaling}

A specific transformation on the scale of the data

z-score standardising, min-max standardisation into {[}0, 1{]} or {[}0,
100{]}, percentage change on the baseline close to variable
transformation step

\textbf{Normalising}

The purpose of normalising is for cross-comparison. This step can get
criticism from analysts for \ldots{}

specifically for converting from a fitted distribution to normal score
via reverse CDF function, non-parametric formula, or empirical
approximation, a common step in many index: SPI, SSI, Z score. The
purpose of normalising is to convert the index into a standardised
series after all the steps for the ease of comparison.

Normalising is usually the last step

\textbf{Variable transformation}

Restrict it to single variable, square root, log etc could be linearly,
also non-linear

change the shape of the variable

GAM, can you do additive model pairwise/ three-way

\textbf{Temporal processing}

\textbf{Dimension reduction}

sometimes called feature extraction in the machine learning community
With drought indices, the extraction of meaningful variables from the
original data is usually supported by the water balance model, for
example, in SPEI, the step that create \(d\) out of precipitation and
potential evapotranspiration (PET) has theoretical backup from {[}see
paper.{]}

Also include weighting

\textbf{Benchmarking}

\textbf{Simplification}

Discretise the continuous index into a few labelled categories. For
communicating the severity of natural hazard to general public.

uniform workflow to work with index construction.

\begin{itemize}
\tightlist
\item
  illustration
\item
  math notation
\item
  benefit of the pipeline approach

  \begin{itemize}
  \tightlist
  \item
    index diagnostic
  \item
    uncertainty
  \end{itemize}
\end{itemize}

\hypertarget{sec-incorporating-new-buliding-blocks-into-the-pipeline}{%
\section{Incorporating new buliding blocks into the
pipeline}\label{sec-incorporating-new-buliding-blocks-into-the-pipeline}}

\hypertarget{sec-examples}{%
\section{Examples}\label{sec-examples}}

\hypertarget{constructing-standardised-precipitation-index-spi}{%
\subsection{Constructing Standardised Precipitation Index
(SPI)}\label{constructing-standardised-precipitation-index-spi}}

\begin{itemize}
\tightlist
\item
  a basic workflow and congruence with results in the \texttt{SPEI} pkg
\item
  allow multiple distribution fit
\item
  allow bootstrap uncertainty
\end{itemize}

\hypertarget{calculating-spei-with-raster-data}{%
\subsection{Calculating SPEI with raster
data}\label{calculating-spei-with-raster-data}}

\hypertarget{reference}{%
\section*{Reference}\label{reference}}
\addcontentsline{toc}{section}{Reference}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-brown_vegetation_2008}{}}%
Brown, Jesslyn F., Brian D. Wardlow, Tsegaye Tadesse, Michael J. Hayes,
and Bradley C. Reed. 2008. {``The {Vegetation} {Drought} {Response}
{Index} ({VegDRI}): {A} {New} {Integrated} {Approach} for {Monitoring}
{Drought} {Stress} in {Vegetation}.''} \emph{GIScience \& Remote
Sensing} 45 (1): 16--46.
\url{https://doi.org/10.2747/1548-1603.45.1.16}.

\leavevmode\vadjust pre{\hypertarget{ref-buja_elements_1988}{}}%
Buja, A, D Asimov, C Hurley, and JA McDonald. 1988. {``Elements of a
Viewing Pipeline for Data Analysis.''} In \emph{Dynamic Graphics for
Statistics}, 277--308. Wadsworth, Belmont.

\leavevmode\vadjust pre{\hypertarget{ref-gli}{}}%
Economist Intelligence Unit. 2019. {``The Global Liveability Index
2019.''} The Economist.
\url{https://www.cbeinternational.ca/pdf/Liveability-Free-report-2019.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-keyantash_aggregate_2004}{}}%
Keyantash, John A., and John A. Dracup. 2004. {``An Aggregate Drought
Index: {Assessing} Drought Severity Based on Fluctuations in the
Hydrologic Cycle and Surface Water Storage.''} \emph{Water Resources
Research} 40 (9). \url{https://doi.org/10.1029/2003WR002610}.

\leavevmode\vadjust pre{\hypertarget{ref-kogan_application_1995}{}}%
Kogan, F. N. 1995. {``Application of Vegetation Index and Brightness
Temperature for Drought Detection.''} \emph{Advances in Space Research},
Natural {Hazards}: {Monitoring} and {Assessment} {Using} {Remote}
{Sensing} {Technique}, 15 (11): 91--100.
\url{https://doi.org/10.1016/0273-1177(95)00079-T}.

\leavevmode\vadjust pre{\hypertarget{ref-mckee1993relationship}{}}%
McKee, Thomas B, Nolan J Doesken, John Kleist, et al. 1993. {``The
Relationship of Drought Frequency and Duration to Time Scales.''} In
\emph{Proceedings of the 8th Conference on Applied Climatology},
17:179--83. 22. Boston, MA, USA.

\leavevmode\vadjust pre{\hypertarget{ref-spi}{}}%
McKee, Thomas B, Nolan J Doesken, and John Kleist. 1993. {``The
Relationship of Drought Frequency and Duration to Time Scales.''} In
\emph{Proceedings of the 8th Conference of Applied Climatology},
179--84. Anaheim, CA: American Meteorological Society.

\leavevmode\vadjust pre{\hypertarget{ref-sutherland_orca_2000}{}}%
Sutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh,
Julie Dickerson, Zach Cox, and Dianne Cook. 2000. {``Orca: {A}
{Visualization} {Toolkit} for {High}-{Dimensional} {Data}.''}
\emph{Journal of Computational and Graphical Statistics} 9 (3): 509--29.
\url{https://www.jstor.org/stable/1390943}.

\leavevmode\vadjust pre{\hypertarget{ref-tucker_red_1979}{}}%
Tucker, Compton J. 1979. {``Red and Photographic Infrared Linear
Combinations for Monitoring Vegetation.''} \emph{Remote Sensing of
Environment} 8 (2): 127--50.
\url{https://doi.org/10.1016/0034-4257(79)90013-0}.

\leavevmode\vadjust pre{\hypertarget{ref-hdi}{}}%
United Nations Development Programme. 2022. {``Human Development Report
2021-22.''} New York. \url{http://report.hdr.undp.org}.

\leavevmode\vadjust pre{\hypertarget{ref-wickham_tidy_2014}{}}%
Wickham, Hadley. 2014. {``Tidy {Data}.''} \emph{Journal of Statistical
Software} 59 (September): 1--23.
\url{https://doi.org/10.18637/jss.v059.i10}.

\leavevmode\vadjust pre{\hypertarget{ref-wickham_plumbing_2009}{}}%
Wickham, Hadley, Michael Lawrence, Dianne Cook, Andreas Buja, Heike
Hofmann, and Deborah F. Swayne. 2009. {``The Plumbing of Interactive
Graphics.''} \emph{Computational Statistics} 24 (2): 207--15.
\url{https://doi.org/10.1007/s00180-008-0116-x}.

\leavevmode\vadjust pre{\hypertarget{ref-xie_reactive_2014}{}}%
Xie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. {``Reactive
{Programming} for {Interactive} {Graphics}.''} \emph{Statistical
Science} 29 (2): 201--13.
\url{https://www.jstor.org/stable/43288470?seq=1}.

\end{CSLReferences}



\end{document}
